{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1.0 Environment Setup\n\nThis cell installs all the necessary libraries for our JAX/Flax project. We use the `-q` flag for a quiet installation.\n\n* **`jax[tpu]`**: Installs JAX with specific optimizations for Google's TPUs.\n* **`flax`**: A neural network library for JAX.\n* **`optax`**: A gradient processing and optimization library for JAX.\n* **`orbax`**: A library for checkpointing (saving model progress).\n* **`transformers` / `datasets`**: Hugging Face libraries for models and data handling.\n* **`wandb`**: For experiment tracking and logging.\n\n> **Note on Warnings:** After this cell runs, you will likely see a long list of red `ERROR` messages about \"dependency conflicts.\" This is **normal and expected** on Kaggle. It happens because our new libraries conflict with older, pre-installed packages we won't be using (like `torch`). These warnings can be safely ignored.","metadata":{}},{"cell_type":"code","source":"!pip install -q \"jax[tpu]\" flax optax orbax-checkpointing transformers datasets wandb ipywidgets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.1 Verify Installation\n\nHere, we import the core libraries we just installed. By printing their versions and checking for available TPU devices, we can confirm that the environment is set up correctly and all dependencies are accessible before proceeding.\n\n\n> **Note on Output:** The output of this cell might include a `TqdmWarning` or an `INFO` message about a `rocm` backend. These are harmless informational messages and do not indicate a problem. A successful run will print your library versions and a list of available TPU devices.","metadata":{}},{"cell_type":"code","source":"import jax\nimport flax\nimport optax\nimport orbax.checkpoint\nimport transformers\nimport datasets\n\n# Print versions to confirm\nprint(f\"JAX version: {jax.__version__}\")\nprint(f\"Flax version: {flax.__version__}\")\nprint(f\"Optax version: {optax.__version__}\")\nprint(f\"Transformers version: {transformers.__version__}\")\nprint(f\"Datasets version: {datasets.__version__}\")\n\n# Check for TPU\ntry:\n    print(\"TPU devices:\", jax.devices(\"tpu\"))\nexcept:\n    print(\"No TPU devices found. Ensure your notebook accelerator is set to TPU.\")\n\nprint(\"\\n✅ All key libraries imported successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T21:37:40.739520Z","iopub.execute_input":"2025-08-20T21:37:40.739766Z","iopub.status.idle":"2025-08-20T21:38:18.629772Z","shell.execute_reply.started":"2025-08-20T21:37:40.739742Z","shell.execute_reply":"2025-08-20T21:38:18.623591Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 TPU Initialization and Authentication\n\nHere, we'll verify that JAX can correctly identify and connect to the available TPU hardware. This step also handles authentication by triggering interactive login prompts for both Hugging Face (to access models) and Weights & Biases (for experiment tracking).\n\n**Note on Output:** This cell will first print the list of available JAX devices, which should show 8 TPU cores. It will then display two separate input boxes. You will need to provide your Hugging Face User Access Token and your Weights & Biases API key in these prompts to proceed.","metadata":{}},{"cell_type":"code","source":"import jax\nfrom huggingface_hub import notebook_login\nimport wandb\n\n# Verify that all 8 TPU cores are visible to JAX\nprint(\"Verifying available JAX devices...\")\nprint(jax.devices())\n\n# Use notebook_login() to prompt for a Hugging Face token\nprint(\"\\nPlease log in to Hugging Face Hub:\")\nnotebook_login()\n\n# Use wandb.login() to prompt for a W&B API key\nprint(\"\\nPlease log in to Weights & Bienses:\")\nwandb.login()\n\nprint(\"\\n✅ Authentication complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3 Data Acquisition and Formatting\n\nThis cell loads the custom dataset from a local `my_dataset.csv` file. It then defines and applies a formatting function to transform the `instruction` and `response` columns into the specific chat template required by Llama 3. The resulting structured text is stored in a new `text` column, and the entire processed dataset is saved to disk for the subsequent tokenization step.\n\n**Note on Output:** The cell will first create the sample CSV file. It will then print a confirmation that the dataset has been loaded, display one complete example of a formatted prompt from the new `text` column, and end with a success message confirming that the data has been saved to the `./processed_data` directory.","metadata":{}},{"cell_type":"code","source":"%%writefile my_dataset.csv\ninstruction,response\n\"How do I get a good sear on a steak in a stainless steel pan?\",\"To get a great sear, preheat your stainless steel pan over medium-high heat until a drop of water sizzles and glides across the surface. Pat your steak completely dry, season it generously, and then place it in the hot, oiled pan. Don't move it for several minutes to allow a deep brown crust to form before flipping.\"\n\"What is the capital of Oklahoma?\",\"The capital of Oklahoma is Oklahoma City.\"\n\"Write a simple Python function to add two numbers.\",\"Certainly! Here's a simple Python function to add two numbers:\\n\\n```python\\ndef add_numbers(a, b):\\n    return a + b\\n```\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport os\n\n# Load the dataset from the local CSV file\ntry:\n    # The output of load_dataset is a DatasetDict, so we access the default 'train' split.\n    dataset = load_dataset('csv', data_files='my_dataset.csv')['train']\n    print(\"Dataset loaded successfully:\")\n    print(dataset)\nexcept FileNotFoundError:\n    print(\"Error: 'my_dataset.csv' not found. Please ensure the file is in the root directory of your Kaggle notebook.\")\n\n# Define the formatting function for the Llama 3 chat template\ndef format_prompt(sample):\n    # This creates the structured text string for each sample\n    sample['text'] = (\n        f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n        f\"{sample['instruction']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n        f\"{sample['response']}<|eot_id|>\"\n    )\n    return sample\n\n# Apply the formatting function to the dataset to create the new 'text' column\nformatted_dataset = dataset.map(format_prompt)\n\n# Verify the new 'text' column by checking the first example\nprint(\"\\n--- Sample of a formatted prompt ---\")\nprint(formatted_dataset[0]['text'])\n\n# Create a directory to save the processed data\noutput_dir = \"./processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Save the processed dataset to disk for the next step\nformatted_dataset.save_to_disk(output_dir)\n\nprint(f\"\\n✅ Formatted dataset saved to '{output_dir}'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}